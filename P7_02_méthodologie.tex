\documentclass[12pt, a4paper]{article}

\usepackage{polyglossia}
	\setdefaultlanguage{french}
\usepackage{fontspec}
	\setmainfont{TeX Gyre Termes}
\usepackage{unicode-math}    
\usepackage{lualatex-math}
	\setmathfont{TeX Gyre Termes Math}
\usepackage[top=2.5cm, bottom=2.5cm, right=2.5cm, left=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{makecell}
    \setcellgapes{8pt}
\usepackage[unicode=true,
%            colorlinks=true,
%            citecolor={green!50!black},
%            urlcolor=blue,
            hidelinks
            ]{hyperref}
\usepackage{tikz}

\begin{document}

\date{mai 2022}
\begin{titlepage}
    \large{\textsc{Leclercq} Lancelot} \hfill \normalsize{Mai 2022}
    \vfill
    \begin{center}
        %\vspace{1cm}
        \huge{Note méthodologique}\\
        \vfill
        \includegraphics[width=.3\textwidth]{logoPAD.png}\\
    \end{center}
    \vfill
    \renewcommand{\contentsname}{Sommaire}
    \pdfbookmark{\contentsname}{toc}
    \tableofcontents
\end{titlepage}

\section{Introduction}

L'entreprise Prêt à dépenser souhaite utiliser un outil de "scoring" afin de calculer la probabilité qu'un client fasse ou non défaut lors du remboursement de son crédit.
Pour cela nous devons entraîner un modèle de classification sur des données variées (comportementales, autres institutions financières, etc).

\section{Classification}
\subsection{Jeu de données}

Afin de mieux comprendre les données nous avons procédé à une analyse exploratoire des données sur le jeu application\_train.csv.
Pour l'entraînement du modèle nous utiliserons uniquement ces données car l'utilisation des fichiers supplémentaires demande beaucoup de ressources tant en temps d'analyse et d'exploration des données qu'en capacités de calculs.
Nous utiliserons le fichier application\_test.csv pour le dashboard.

\subsection{"Feature engeneering"}

Calcul de variables polynomiales à partir des meilleurs variables (EXT\_SOURCES).
Il n'y a pas d'amélioration significative des résultats (Fig. \ref{fig:ScoresGridFull})

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=\textwidth]{./Figures/ScoresGridfull.pdf}
    \end{center}
    \caption{Comparaisons des différents scores avec (\_featEng) et sans (\_base) variables polynomiales}
    \label{fig:ScoresGridFull}
\end{figure}

\subsection{Déséquilibre des valeurs cible}

Du fait d'un déséquilibre dans les valeurs cible il est difficile pour le modèle de classer efficacement les clients (Fig. \ref{fig:DéséquilibreCible}).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=.7\textwidth]{./Figures/DéséquilibreCible.pdf}
    \end{center}
    \caption{Diagramme circulaire illustrant le déséquilibre des types de clients dans la colonne cible}
    \label{fig:DéséquilibreCible}
\end{figure}

Lors de l'optimisation du score AUC le modèle va préférer classer tous les clients comme ne faisant pas défaut car cela améliorera son score.
Nous avons donc dû rééquilibrer la part des valeurs cible grâce à la librairie imblearn.
Cette librairie propose des outils de sur- et de sous-échantillonnage.

Le sur-échantillonnage (over-sampling) permet d'augmenter le nombre de cibles faisant défaut.
Soit en dédoublant aléatoirement des cibles faisant défaut (random over sampling).
Soit en créant des données synthétiques (SMOTE) à partir de cibles voisines (KNN)

Le sous-échantillonnage (under-sampling) permet de diminuer le nombre de cibles ne faisant pas défaut.
Soit en échantillonnant aléatoirement un nombre de cible ne faisant pas défaut égale au nombre de cible faisant défaut (random under sampling)
Soit en créant des données (Tomek links) à partir de groupe de cibles ne faisant pas défaut (KNN)

Un mélange de sur- et de sous-échantillonnage avec SMOTEENN et SMOTETomek qui combinent les effets de SMOTE avec une réduction à partir des plus proches voisins

\subsection{Modèles}

Nous avons utilisé deux modèles XGBoost et LightGBM qui ont l'avantage d'être résistants aux valeurs manquantes. Ces deux modèles reposent sur le boosting de gradient qui consiste en une agrégation d'arbres de décisions simples afin d'obtenir un meilleur résultat

\section{Évaluation, coût métier et optimisation}

\subsection{Courbe ROC et aire sous la courbe (AUC)}

La courbe ROC représente les vrais positifs en fonction des faux positifs (Fig. \ref{fig:ROCCurves}).
Plus la courbe est proche du coin supérieur gauche meilleur est le modèle.
L'aire sous la courbe (AUC) nous donne une valeur numérique pour comparer ces modèles.

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=.7\textwidth]{./Figures/CurvesROCGridBest_base.pdf}
    \end{center}
    \caption{Courbes ROC pour les deux modèles dont nous avons testé les hyperparamètres}
    \label{fig:ROCCurves}
\end{figure}

\subsection{Coût métier}

Afin d'utiliser une méthode d'évaluation qui soit mathématiquement fondée nous nous sommes basé sur une métrique déjà existante du F-score.
Ce score calcul la moyenne harmonique de la précision et du rappel (Fig. \ref{fig:ConfMatrix}).
L'utilisation du F\textsubscript{β}-score permet d'ajouter du poids respectivement au rappel lorsque le facteur β est \num{>1} ou à la précision lorsque le facteur β est \num{<1}.
Nous avons utilisé une valeur de β=2

\begin{figure}[h]
    \begin{center}
        \begin{tikzpicture}
            \node[anchor=south west,inner sep=0] (image) at (0,0) { {\makegapedcells
                        \begin{tabular}{cc|cc}
                            \multicolumn{2}{c}{}
                             & \multicolumn{2}{c}{Prédit}           \\
                             &                            & 0  & 1  \\
                            \cline{2-4}
                            \multirow{2}{*}{\rotatebox[origin=c]{90}{Réel}}
                             & 0                          & TN & FP \\
                             & 1                          & FN & TP \\
                            \cline{2-4}
                        \end{tabular}}};
            \begin{scope}[x={(image.south east)},y={(image.north west)}]
                \draw[red, ultra thick] (0.7,0.12) circle [x radius=1cm, y radius=.4cm];
                \node[rectangle,below] at (0.7,-0.05) (R) {Recall};
                \draw[green, ultra thick] (0.87,0.25) circle [x radius=.5cm, y radius=.9cm];
                \node[rectangle,right] at (1,0.25) (P) {Precision};
                %\draw[help lines,xstep=.1,ystep=.1] (0,0) grid (1,1);
                %\foreach \x in {0,1,...,9} { \node [anchor=north] at (\x/10,0) {0.\x}; }
                %\foreach \y in {0,1,...,9} { \node [anchor=east] at (0,\y/10) {0.\y}; }

            \end{scope}
        \end{tikzpicture}
    \end{center}
    \caption{Matrice de confusion rappelant ce que sont la précision et le rappel}
    \label{fig:ConfMatrix}
\end{figure}

\subsection{Optimisation}

L'optimisation a été effectuée par GridSearch. Pour chaque solution de rééquilibrage nous avons fait une GridSearch pour les deux modèles. Pour la classification avec XGBoost nous avons testé trois solutions avec un nombre de boosting de 100, 500 ou 1000.
Pour LightGBM nous avons testé différents algorithmes : GBDT, DART, RF et GOSS et différents nombre de boosting : 100, 500 et 1000.
Nous avons retenu comme meilleur modèle LightGBM avec un sur-échantillonnage aléatoire (random over sampling). Les paramètres retenus sont l'algorithme DART et un nombre de boosting de 100

\section{Interprétabilité}

Dans un souci de transparence nous souhaitons pouvoir expliquer comment fonctionnent nos modèles

\subsection{Globale}

L'étude des principales variables utilisées par le modèle permet de mieux comprendre son fonctionnement global (Fig. \ref{fig:BestFeat})

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=.9\textwidth]{./Figures/BestFeatGridF2_base.pdf}
    \end{center}
    \caption{Principales variables selon leur importance dans l'entraînement des modèles}
    \label{fig:BestFeat}
\end{figure}

Nous avons utilisé la librairie SHAP afin d'expliquer le modèle retenu (LightGBM). Celle-ci nous permet d'observer la part des différentes variables dans la classification dans l'une ou l'autre des classes (Fig. \ref{fig:shapSummary}).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=.5\textwidth]{./Figures/shapSummary.pdf}
    \end{center}
    \caption{Part des principales variables dans la classification}
    \label{fig:shapSummary}
\end{figure}

\subsection{Locale}

La librairie SHAP nous permet d'en apprendre un peu plus sur la part des variables dans le classement d'un client en particulier (Fig. \ref{fig:shapWaterfall}).

\begin{figure}[h]
    \begin{center}
        \includegraphics[width=.9\textwidth]{./Figures/shapForce}
        \includegraphics[width=.6\textwidth]{./Figures/shapWaterfall.pdf}
    \end{center}
    \caption{Part des variables dans la classification d'un client}
    \label{fig:shapWaterfall}
\end{figure}

\section{Limites et améliorations}

Nous pourrions essayer d'optimiser plus d'hyperparamètres dans les différents modèles afin d'améliorer encore les résultats



\end{document}